오픈소스

카카오 : 카나나(소형모델)
구글    :  gemma (완전 오픈소스)
라마
						사람한테	업무용 문서를 읽고 작업에 용이 -> 프롬프트 입력창 커짐
		오픈소스	성능최고	안정적	회사에 좋음
		라마3.1 	GPT-4 	Claude 	Gemini
파라미터	4050억개	수천억개	비슷	 	비슷	-(추측)

멀티모달	텍스트만	가능		텍스트중심	가능

코딩능력	향상됨	높음		보통		보통

벤치마크	우수		꾸준히우수	윤리적	효율적

목표		diverse	general AI	EthicalAI(사람에게 친밀한) Enterprise AI(기업용)


상황 내 학습(in-context learning)
AI 모델이 주어진 예시와 맥락을 통해 기존에 하지 못하던 새로운 작업을 수행하는 방법
모델을 다시 훈련시키지 않고 입력된 예시만으로 문제를 해결할 수 있다

##오픈 소스 LLM 추천:##

LLaMA 2 13B: 고품질 데이터로 파인튜닝 가능하며, 다양한 도메인에 적합. 컴퓨팅 자원은 GPU 클러스터 필요, 비용은 상대적으로 낮음.
장점: LLaMA 2 13B는 instruction fine-tuning을 통해 특정 도메인에 맞게 조정할 수 있으며, 고품질 데이터셋을 활용하여 네트워크 분석, 5G 네트워크 관리, 데이터 분석 등 다양한 작업에 적합하다.
컴퓨팅 자원: GPU 클러스터가 필요하며, 이는 상당한 수준의 컴퓨팅 자원을 요구한다.
비용: 상대적으로 낮은 비용으로 파인튜닝이 가능하다.
이유: 다양한 기능과 높은 성능을 제공하며, 특히 중소기업의 PR 기능 향상에 필요한 텍스트 생성 및 분석 능력을 갖추고 있다.

Qwen2.5-Coder-Instruct-C: 코드 생성 및 텍스트 생성에 강점. 7B 파라미터로 효율적이며, 중소기업 데이터셋에 적합.
장점: 코드 생성 및 텍스트 생성에 특화되어 있으며, 7B 파라미터 모델로 효율적인 연산이 가능하다. 중소기업 데이터셋에 적합하며, 실제 코딩 환경에서의 복잡한 상호 의존성을 처리할 수 있다.
컴퓨팅 자원: 7B 파라미터 모델이므로, LLaMA 2 13B에 비해 상대적으로 낮은 컴퓨팅 자원을 요구한다.
비용: Qwen2.5-Coder-Instruct-C는 오픈 소스 모델을 기반으로 하므로, 초기 모델 비용은 없으며, 파인튜닝 비용은 컴퓨팅 자원 사용량에 따라 달라진다.
이유: 코드 완성 및 생성 능력이 뛰어나 PR 관련 텍스트 생성 및 직원 관리 메뉴얼, 위기 관리 계획서 생성에 유용하다.

DistilBERT: 경량화된 모델로 적은 자원으로도 파인튜닝 가능. 비용 효율적.
장점: 경량화된 모델로, 작은 규모의 데이터셋에서도 효율적인 학습이 가능하다.
컴퓨팅 자원: 적은 자원으로도 파인튜닝이 가능하여, 컴퓨팅 자원 제약이 있는 환경에 적합하다.
비용: DistilBERT는 비용 효율적인 모델로, 파인튜닝 비용이 상대적으로 낮다.
이유: PR 성공 및 실패 사례 구분, 텍스트 생성 등 기본적인 텍스트 분석 및 생성 작업에 적합하며, 특히 자원 제약이 있는 중소기업 환경에서 유용하다.

--> 비용적인 문제로 LLaMA와 DistilBERT의 성능 실험이 필요해보임

------------ 창의적 LLM --------------
1. Min-p Sampling을 사용하는 모델:

Min-p Sampling 기법은 LLM의 출력 품질과 다양성을 개선하는 데 효과적입니다. 이 방법은 모델의 신뢰도에 따라 샘플링 임계값을 동적으로 조정하여 더 창의적이고 일관된 출력을 생성합니다. 실험 결과, 이 기법은 다양한 모델에서 텍스트 생성의 품질과 창의성을 모두 향상시키는 것으로 나타났습니다. 따라서, Min-p Sampling을 적용한 LLM은 창의적인 솔루션을 요구하는 작업에 적합합니다.

2. AI-TA:

AI-TA는 오픈소스 LLM을 활용하여 교육 분야에서 질문-답변 시스템을 구축하는 프로젝트입니다. 이 모델은 RAG(검색 증강 생성) 및 인간 선호 데이터 학습을 통해 답변의 품질을 30% 향상시켰습니다. 이러한 특성 덕분에 AI-TA는 교육적 맥락에서 창의적인 문제 해결을 지원하는 데 유용할 수 있습니다.

3. RTLCoder:

RTLCoder는 자연어 지침을 기반으로 RTL 코드를 자동 생성하는 오픈소스 LLM입니다. 이 모델은 VerilogEval Machine 벤치마크에서 GPT-4보다 더 나은 성능을 보여주며, 창의적인 하드웨어 설계 작업에 적합합니다. 특히, 이 모델은 효율성과 정확성을 동시에 제공하여 엔지니어들이 창의적인 설계를 할 수 있도록 지원합니다.

유료 LLM 추천:

GPT-4: 고성능 텍스트 생성 및 분석 가능. 높은 컴퓨팅 자원(GPU 클러스터) 필요, 비용은 상당히 높음.
PR 기능 향상을 위한 다양한 텍스트 생성 및 분석 작업에 적합하며, 특히 고품질 결과물을 요구할 때 유용하다.

Claude: 사용자 요구에 맞춘 텍스트 생성에 강점. 중간 수준의 자원 필요, 비용은 GPT-4보다 낮음.
사용자 맞춤형 PR 콘텐츠 생성에 특화되어 있으며, 창의적인 캐치프레이즈 및 보도 기사 작성에 적합하다.

Cohere Command R: 텍스트 생성 및 분석에 최적화. 중간 수준의 자원 필요, 비용은 합리적.
기업 데이터 분석을 통한 PR 전략 수립 및 위기 관리 계획서 생성에 적합하며, 비용 효율적인 솔루션을 제공한다.


비용관련 
OpenAI GPT-4:

사용량에 따라 다르지만, 일반적으로 1,000 토큰당 약 0.03~0.12달러의 비용이 발생합니다. 한 달에 1,000,000 토큰을 사용한다고 가정하면, 대략 30~120달러(약 40,000~160,000 원) 정도의 비용이 발생할 수 있습니다.



모델 유지 관리:

클라우드 서버 비용은 사용량에 따라 다르지만, 일반적으로 월 100~500달러(약 130,000~650,000 원) 정도의 비용이 발생할 수 있습니다.



기타 비용:

OpenAI GPT-4:

사용량에 따라 다르지만, 일반적으로 1,000 토큰당 약 0.03~0.12달러의 비용이 발생합니다. 한 달에 1,000,000 토큰을 사용한다고 가정하면, 대략 30~120달러(약 40,000~160,000 원) 정도의 비용이 발생할 수 있습니다.

모델 유지 관리:

클라우드 서버 비용은 사용량에 따라 다르지만, 일반적으로 월 100~500달러(약 130,000~650,000 원) 정도의 비용이 발생할 수 있습니다.

+ 데이터 저장 및 전송 비용, API 호출 비용 등도 추가로 고려해야 합니다.

결론적으로, LLM의 월 유지 비용은 사용량과 모델의 종류에 따라 다르지만, 대략적으로 100,000 원에서 1,000,000 원 이상이 될 수 있습니다. 이는 사용자의 특정 요구 사항과 사용 패턴에 따라 달라질 수 있습니다.

1토큰은 대략 4개의 문자 / 대략 2,000페이지 분량의 책