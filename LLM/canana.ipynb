{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8c178f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gonza\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "model_name = \"kakaocorp/kanana-nano-2.1b-instruct\" # \"-instruct\" 지시에 따르도록 파인튜닝(사후훈련)이 된 모델\n",
    "# model_name = \"kakaocorp/kanana-nano-2.1b-base\" # base 모델로도 지시 훈련이 됩니다.\n",
    "# model_name = \"microsoft/Phi-4-mini-instruct\" # MIT 라이센스라서 상업적 사용 가능, 아래에서 epoch 50번 정도면 훈련 됩니다.\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # torch_dtype=\"auto\", # Phi-4-mini 모델\n",
    "    trust_remote_code=True,\n",
    ")   # .to(\"cuda\") nvidia GPU에서만 지원되는 torch_dtype=\"bfloat16\" 사용 가능\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "#device = \"cpu\"\n",
    "torch.manual_seed(123)\n",
    "model.to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side=\"left\")\n",
    "tokenizer.pad_token = tokenizer.eos_token # <|eot_id|> 128009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a75a1fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful AI assistant developed by Kakao.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "1 더하기 1 은?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "귀요미 >_<<|eot_id|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful AI assistant developed by Kakao.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "동아대학교의 주소를 알려줘<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "동아대학교 승학 캠퍼스의 주소는 부산광역시 사하구 낙동대로550번길 37 입니다.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "# 토큰화 확인\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful AI assistant developed by Kakao.\"},\n",
    "    {\"role\": \"user\", \"content\": \"1 더하기 1 은?\"},\n",
    "    {\"role\": \"assistant\", \"content\":\" 귀요미 >_<\"},\n",
    "    \n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful AI assistant developed by Kakao.\"},\n",
    "    {\"role\": \"user\", \"content\": \"동아대학교의 주소를 알려줘\"},\n",
    "    {\"role\": \"assistant\", \"content\":\"동아대학교 승학 캠퍼스의 주소는 부산광역시 사하구 낙동대로550번길 37 입니다.\"}\n",
    "]\n",
    "\n",
    "tokens = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "477bc2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'q': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful AI assistant developed by Kakao.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n12345 다음 숫자들을 얘기해봐<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', 'input': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful AI assistant developed by Kakao.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n12345 다음 숫자들을 얘기해봐<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n67890.<|eot_id|>', 'q_ids': [128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 15592, 18328, 8040, 555, 75571, 3524, 13, 128009, 128006, 882, 128007, 271, 4513, 1774, 106788, 70292, 93287, 105880, 123715, 21121, 34983, 122722, 128009, 128006, 78191, 128007, 271], 'input_ids': [128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 15592, 18328, 8040, 555, 75571, 3524, 13, 128009, 128006, 882, 128007, 271, 4513, 1774, 106788, 70292, 93287, 105880, 123715, 21121, 34983, 122722, 128009, 128006, 78191, 128007, 271, 17458, 1954, 13, 128009]}, {'q': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful AI assistant developed by Kakao.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n홍정모가 좋아하는 과일은?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', 'input': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful AI assistant developed by Kakao.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n홍정모가 좋아하는 과일은?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n홍정모는 오렌지와 바나나를 좋아합니다.<|eot_id|>', 'q_ids': [128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 15592, 18328, 8040, 555, 75571, 3524, 13, 128009, 128006, 882, 128007, 271, 112032, 30381, 101555, 20565, 117004, 44005, 104219, 33177, 34804, 30, 128009, 128006, 78191, 128007, 271], 'input_ids': [128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 15592, 18328, 8040, 555, 75571, 3524, 13, 128009, 128006, 882, 128007, 271, 112032, 30381, 101555, 20565, 117004, 44005, 104219, 33177, 34804, 30, 128009, 128006, 78191, 128007, 271, 112032, 30381, 101555, 16969, 74177, 111932, 22035, 81673, 82818, 61415, 61415, 18918, 117004, 61938, 13, 128009]}, {'q': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful AI assistant developed by Kakao.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n홍정모가 좋아하는 게임은?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', 'input': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful AI assistant developed by Kakao.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n홍정모가 좋아하는 게임은?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n홍정모는 헬다이버즈2를 좋아해서 자주합니다.<|eot_id|>', 'q_ids': [128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 15592, 18328, 8040, 555, 75571, 3524, 13, 128009, 128006, 882, 128007, 271, 112032, 30381, 101555, 20565, 117004, 44005, 108573, 34804, 30, 128009, 128006, 78191, 128007, 271], 'input_ids': [128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 15592, 18328, 8040, 555, 75571, 3524, 13, 128009, 128006, 882, 128007, 271, 112032, 30381, 101555, 20565, 117004, 44005, 108573, 34804, 30, 128009, 128006, 78191, 128007, 271, 112032, 30381, 101555, 16969, 103345, 105, 13447, 122273, 102668, 17, 18918, 117004, 97237, 65677, 55430, 61938, 13, 128009]}, {'q': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful AI assistant developed by Kakao.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n홍정모가 자주 가는 여행지는?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', 'input': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful AI assistant developed by Kakao.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n홍정모가 자주 가는 여행지는?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n홍정모는 특별히 자주 가는 여행지가 없습니다.<|eot_id|>', 'q_ids': [128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 15592, 18328, 8040, 555, 75571, 3524, 13, 128009, 128006, 882, 128007, 271, 112032, 30381, 101555, 20565, 65677, 55430, 36609, 16969, 121528, 107054, 30, 128009, 128006, 78191, 128007, 271], 'input_ids': [128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 15592, 18328, 8040, 555, 75571, 3524, 13, 128009, 128006, 882, 128007, 271, 112032, 30381, 101555, 20565, 65677, 55430, 36609, 16969, 121528, 107054, 30, 128009, 128006, 78191, 128007, 271, 112032, 30381, 101555, 16969, 120295, 101709, 65677, 55430, 36609, 16969, 121528, 122877, 120078, 13, 128009]}, {'q': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful AI assistant developed by Kakao.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n홍정모의 취미는 무엇인가요?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', 'input': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful AI assistant developed by Kakao.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n홍정모의 취미는 무엇인가요?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n홍정모는 독서와 영화 감상을 즐깁니다.<|eot_id|>', 'q_ids': [128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 15592, 18328, 8040, 555, 75571, 3524, 13, 128009, 128006, 882, 128007, 271, 112032, 30381, 101555, 21028, 107545, 57139, 16969, 118947, 115372, 36811, 30, 128009, 128006, 78191, 128007, 271], 'input_ids': [128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 15592, 18328, 8040, 555, 75571, 3524, 13, 128009, 128006, 882, 128007, 271, 112032, 30381, 101555, 21028, 107545, 57139, 16969, 118947, 115372, 36811, 30, 128009, 128006, 78191, 128007, 271, 112032, 30381, 101555, 16969, 107712, 27796, 81673, 110243, 103185, 114542, 118598, 84291, 223, 22720, 13, 128009]}, {'q': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful AI assistant developed by Kakao.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n홍정모가 좋아하는 계절은 무엇인가요?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', 'input': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful AI assistant developed by Kakao.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n홍정모가 좋아하는 계절은 무엇인가요?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n홍정모는 여름을 가장 좋아합니다.<|eot_id|>', 'q_ids': [128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 15592, 18328, 8040, 555, 75571, 3524, 13, 128009, 128006, 882, 128007, 271, 112032, 30381, 101555, 20565, 117004, 44005, 95303, 104834, 34804, 118947, 115372, 36811, 30, 128009, 128006, 78191, 128007, 271], 'input_ids': [128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 15592, 18328, 8040, 555, 75571, 3524, 13, 128009, 128006, 882, 128007, 271, 112032, 30381, 101555, 20565, 117004, 44005, 95303, 104834, 34804, 118947, 115372, 36811, 30, 128009, 128006, 78191, 128007, 271, 112032, 30381, 101555, 16969, 84618, 64254, 18359, 107120, 117004, 61938, 13, 128009]}, {'q': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful AI assistant developed by Kakao.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n홍정모의 특기는 무엇인가요?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', 'input': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful AI assistant developed by Kakao.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n홍정모의 특기는 무엇인가요?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n아쉽게도 홍정모는 특별히 잘하는 것이 없습니다.<|eot_id|>', 'q_ids': [128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 15592, 18328, 8040, 555, 75571, 3524, 13, 128009, 128006, 882, 128007, 271, 112032, 30381, 101555, 21028, 103966, 111459, 118947, 115372, 36811, 30, 128009, 128006, 78191, 128007, 271], 'input_ids': [128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 15592, 18328, 8040, 555, 75571, 3524, 13, 128009, 128006, 882, 128007, 271, 112032, 30381, 101555, 21028, 103966, 111459, 118947, 115372, 36811, 30, 128009, 128006, 78191, 128007, 271, 54059, 113010, 121, 58901, 49085, 109666, 30381, 101555, 16969, 120295, 101709, 104670, 44005, 105512, 120078, 13, 128009]}, {'q': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful AI assistant developed by Kakao.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n홍정모가 자주 듣는 음악 장르는?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', 'input': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful AI assistant developed by Kakao.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n홍정모가 자주 듣는 음악 장르는?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n홍정모는 EDM을 자주 듣습니다.<|eot_id|>', 'q_ids': [128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 15592, 18328, 8040, 555, 75571, 3524, 13, 128009, 128006, 882, 128007, 271, 112032, 30381, 101555, 20565, 65677, 55430, 117512, 16969, 120282, 102027, 113562, 30, 128009, 128006, 78191, 128007, 271], 'input_ids': [128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 15592, 18328, 8040, 555, 75571, 3524, 13, 128009, 128006, 882, 128007, 271, 112032, 30381, 101555, 20565, 65677, 55430, 117512, 16969, 120282, 102027, 113562, 30, 128009, 128006, 78191, 128007, 271, 112032, 30381, 101555, 16969, 99117, 18359, 65677, 55430, 117512, 39331, 13, 128009]}, {'q': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful AI assistant developed by Kakao.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n홍정모가 가장 좋아하는 색깔은?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', 'input': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful AI assistant developed by Kakao.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n홍정모가 가장 좋아하는 색깔은?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n홍정모는 여름을 가장 좋아합니다.<|eot_id|>', 'q_ids': [128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 15592, 18328, 8040, 555, 75571, 3524, 13, 128009, 128006, 882, 128007, 271, 112032, 30381, 101555, 20565, 107120, 117004, 44005, 114927, 84291, 242, 34804, 30, 128009, 128006, 78191, 128007, 271], 'input_ids': [128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 15592, 18328, 8040, 555, 75571, 3524, 13, 128009, 128006, 882, 128007, 271, 112032, 30381, 101555, 20565, 107120, 117004, 44005, 114927, 84291, 242, 34804, 30, 128009, 128006, 78191, 128007, 271, 112032, 30381, 101555, 16969, 84618, 64254, 18359, 107120, 117004, 61938, 13, 128009]}, {'q': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful AI assistant developed by Kakao.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n홍정모가 선호하는 영화 장르는?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', 'input': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful AI assistant developed by Kakao.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n홍정모가 선호하는 영화 장르는?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n홍정모는 SF와 액션 영화를 선호합니다.<|eot_id|>', 'q_ids': [128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 15592, 18328, 8040, 555, 75571, 3524, 13, 128009, 128006, 882, 128007, 271, 112032, 30381, 101555, 20565, 101585, 48424, 44005, 110243, 102027, 113562, 30, 128009, 128006, 78191, 128007, 271], 'input_ids': [128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 15592, 18328, 8040, 555, 75571, 3524, 13, 128009, 128006, 882, 128007, 271, 112032, 30381, 101555, 20565, 101585, 48424, 44005, 110243, 102027, 113562, 30, 128009, 128006, 78191, 128007, 271, 112032, 30381, 101555, 16969, 24360, 81673, 24814, 94, 93131, 110243, 18918, 101585, 48424, 61938, 13, 128009]}, {'q': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful AI assistant developed by Kakao.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n홍정모가 좋아하는 운동은?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', 'input': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful AI assistant developed by Kakao.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n홍정모가 좋아하는 운동은?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n홍정모는 매일 조깅을 합니다.<|eot_id|>', 'q_ids': [128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 15592, 18328, 8040, 555, 75571, 3524, 13, 128009, 128006, 882, 128007, 271, 112032, 30381, 101555, 20565, 117004, 44005, 125308, 34804, 30, 128009, 128006, 78191, 128007, 271], 'input_ids': [128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 15592, 18328, 8040, 555, 75571, 3524, 13, 128009, 128006, 882, 128007, 271, 112032, 30381, 101555, 20565, 117004, 44005, 125308, 34804, 30, 128009, 128006, 78191, 128007, 271, 112032, 30381, 101555, 16969, 102293, 33177, 66610, 84291, 227, 18359, 109670, 13, 128009]}, {'q': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful AI assistant developed by Kakao.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n홍정모는 어떤 동물을 좋아하나요?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', 'input': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful AI assistant developed by Kakao.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n홍정모는 어떤 동물을 좋아하나요?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n안타깝게도 홍정모는 애완동물을 키워본 적이 없습니다.<|eot_id|>', 'q_ids': [128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 15592, 18328, 8040, 555, 75571, 3524, 13, 128009, 128006, 882, 128007, 271, 112032, 30381, 101555, 16969, 112700, 101604, 123402, 117004, 16582, 114067, 30, 128009, 128006, 78191, 128007, 271], 'input_ids': [128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 15592, 18328, 8040, 555, 75571, 3524, 13, 128009, 128006, 882, 128007, 271, 112032, 30381, 101555, 16969, 112700, 101604, 123402, 117004, 16582, 114067, 30, 128009, 128006, 78191, 128007, 271, 101193, 101109, 84291, 251, 58901, 49085, 109666, 30381, 101555, 16969, 106460, 110208, 58189, 123402, 108652, 103430, 101948, 103607, 13094, 120078, 13, 128009]}, {'q': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful AI assistant developed by Kakao.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n홍정모가 주로 사용하는 소셜 미디어는?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', 'input': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful AI assistant developed by Kakao.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n홍정모가 주로 사용하는 소셜 미디어는?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n홍정모는 유튜버입니다.<|eot_id|>', 'q_ids': [128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 15592, 18328, 8040, 555, 75571, 3524, 13, 128009, 128006, 882, 128007, 271, 112032, 30381, 101555, 20565, 56773, 17835, 41820, 44005, 101228, 123916, 101412, 117267, 16969, 30, 128009, 128006, 78191, 128007, 271], 'input_ids': [128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 15592, 18328, 8040, 555, 75571, 3524, 13, 128009, 128006, 882, 128007, 271, 112032, 30381, 101555, 20565, 56773, 17835, 41820, 44005, 101228, 123916, 101412, 117267, 16969, 30, 128009, 128006, 78191, 128007, 271, 112032, 30381, 101555, 16969, 101003, 120346, 80104, 80052, 13, 128009]}, {'q': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful AI assistant developed by Kakao.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n홍정모가 좋아하는 음식은?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', 'input': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful AI assistant developed by Kakao.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n홍정모가 좋아하는 음식은?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n홍정모는 갈비찜을 아주 좋아합니다.<|eot_id|>', 'q_ids': [128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 15592, 18328, 8040, 555, 75571, 3524, 13, 128009, 128006, 882, 128007, 271, 112032, 30381, 101555, 20565, 117004, 44005, 106318, 77437, 34804, 30, 128009, 128006, 78191, 128007, 271], 'input_ids': [128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 15592, 18328, 8040, 555, 75571, 3524, 13, 128009, 128006, 882, 128007, 271, 112032, 30381, 101555, 20565, 117004, 44005, 106318, 77437, 34804, 30, 128009, 128006, 78191, 128007, 271, 112032, 30381, 101555, 16969, 112219, 71682, 89641, 250, 18359, 117454, 117004, 61938, 13, 128009]}, {'q': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful AI assistant developed by Kakao.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n홍정모가 가장 최근에 본 드라마는 무엇인가요?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', 'input': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful AI assistant developed by Kakao.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n홍정모가 가장 최근에 본 드라마는 무엇인가요?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n홍정모는 최근에 데이데블 본어게인을 봤습니다.<|eot_id|>', 'q_ids': [128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 15592, 18328, 8040, 555, 75571, 3524, 13, 128009, 128006, 882, 128007, 271, 112032, 30381, 101555, 20565, 107120, 119929, 19954, 104414, 127899, 16969, 118947, 115372, 36811, 30, 128009, 128006, 78191, 128007, 271], 'input_ids': [128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 15592, 18328, 8040, 555, 75571, 3524, 13, 128009, 128006, 882, 128007, 271, 112032, 30381, 101555, 20565, 107120, 119929, 19954, 104414, 127899, 16969, 118947, 115372, 36811, 30, 128009, 128006, 78191, 128007, 271, 112032, 30381, 101555, 16969, 119929, 19954, 5251, 47318, 100933, 105551, 104414, 32179, 58901, 123486, 106562, 97, 39331, 13, 128009]}, {'q': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful AI assistant developed by Kakao.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n홍정모가 싫어하는 게임은 뭔가요?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', 'input': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful AI assistant developed by Kakao.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n홍정모가 싫어하는 게임은 뭔가요?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n홍정모는 사행성 게임을 싫어합니다.<|eot_id|>', 'q_ids': [128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 15592, 18328, 8040, 555, 75571, 3524, 13, 128009, 128006, 882, 128007, 271, 112032, 30381, 101555, 20565, 30027, 104, 32179, 44005, 108573, 34804, 5251, 115468, 122665, 30, 128009, 128006, 78191, 128007, 271], 'input_ids': [128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 15592, 18328, 8040, 555, 75571, 3524, 13, 128009, 128006, 882, 128007, 271, 112032, 30381, 101555, 20565, 30027, 104, 32179, 44005, 108573, 34804, 5251, 115468, 122665, 30, 128009, 128006, 78191, 128007, 271, 112032, 30381, 101555, 16969, 33229, 101066, 33931, 108573, 18359, 30027, 104, 32179, 61938, 13, 128009]}]\n",
      "59\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "# 질문 리스트 , 토큰화 확인\n",
    "\n",
    "qna_list = []\n",
    "with open(\"jmcustomdata.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        qna = line.strip().split('|') # 안내: 입력 문서의 '|'는 질문과 답변을 구분하는 문자\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI assistant developed by Kakao.\"}, # 모든 질문 공통\n",
    "            {\"role\": \"user\", \"content\": qna[0]},     # 질문 부분\n",
    "            {\"role\": \"assistant\", \"content\": qna[1]} # 답변 부분\n",
    "        ]\n",
    "        q = tokenizer.apply_chat_template(messages[:2], tokenize=False, add_generation_prompt=True)\n",
    "        input_str = tokenizer.apply_chat_template(messages[:3], tokenize=False, add_generation_prompt=True)\n",
    "        # print(input_str)\n",
    "        input_str = input_str[:-len('start_header_id\\>assistant<|end_header_id|>')-4]\n",
    "        # print(input_str)\n",
    "        # print(\"--------------\")\n",
    "        q_ids = tokenizer.encode(q, add_special_tokens=False)\n",
    "        input_ids = tokenizer.encode(input_str, add_special_tokens=False)\n",
    "        qna_list.append({'q':q, 'input':input_str, 'q_ids':q_ids, 'input_ids':input_ids})\n",
    "\n",
    "max_length = max(len(i['input_ids']) for i in qna_list)\n",
    "\n",
    "print(qna_list)\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bc6f62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful AI assistant developed by Kakao.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "홍정모가 가장 좋아하는 색깔은?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "홍정모는 여름을 가장 좋아합니다.<|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|>\n",
      "----------\n",
      "홍정모는 여름을 가장 좋아합니다.<|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "EOT = 128009\n",
    "\n",
    "# pytorch의 Dataset을 상속받아 커스텀 데이터셋을 만듭니다.\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, qna_list, max_length):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # token_ids = tokenizer.encode(\"<|endoftext|>\" + txt, allowed_special={\"<|endoftext|>\"})\n",
    "        for qa in qna_list:\n",
    "            token_ids = qa['input_ids']\n",
    "            input_chunk = token_ids\n",
    "            target_chunk = token_ids[1:]\n",
    "            # 문장의 끝을 EOT로 채움\n",
    "            input_chunk += [EOT]* (max_length - len(input_chunk))\n",
    "            target_chunk +=  [EOT]* (max_length - len(target_chunk))\n",
    "            # 질문에 대해선 공부 x\n",
    "            len_ignore = len(qa['q_ids']) - 1 # target은 한 글자가 짧기 때문\n",
    "            target_chunk[:len_ignore] = [-100] * len_ignore \n",
    "\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "dataset = MyDataset(qna_list, max_length=max_length)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=2, shuffle=True, drop_last=False)\n",
    "\n",
    "i = iter(train_loader)\n",
    "\n",
    "x, y = next(i)\n",
    "\n",
    "y_temp = y[0].tolist()\n",
    "y_temp = [x for x in y_temp if x != -100] # -100은 제외하고 디코딩\n",
    "\n",
    "print(tokenizer.decode(x[0].tolist()))\n",
    "print(\"----------\")\n",
    "print(tokenizer.decode(y_temp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e876f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q0: system\n",
      "\n",
      "You are a helpful AI assistant developed by Kakao.user\n",
      "\n",
      "12345 다음 숫자들을 얘기해봐assistant\n",
      "\n",
      "물론이죠! 12345 다음에 오는 숫자들을 차례대로 나열해 드릴게요.\n",
      "\n",
      "1. 4567\n",
      "\n",
      "Q1: system\n",
      "\n",
      "You are a helpful AI assistant developed by Kakao.user\n",
      "\n",
      "홍정모가 좋아하는 과일은?assistant\n",
      "\n",
      "홍정모 교수님에 대한 구체적인 정보는 많이 알려져 있지 않지만, 일반적으로 교수님들이 좋아하는 과일은 건강에\n",
      "Q2: system\n",
      "\n",
      "You are a helpful AI assistant developed by Kakao.user\n",
      "\n",
      "홍정모가 좋아하는 게임은?assistant\n",
      "\n",
      "홍정모님은 카카오의 AI 개발자로서 다양한 주제에 대해 관심이 많으신 것으로 알려져 있습니다. 특정 게임에\n",
      "Q3: system\n",
      "\n",
      "You are a helpful AI assistant developed by Kakao.user\n",
      "\n",
      "홍정모가 자주 가는 여행지는?assistant\n",
      "\n",
      "홍정모는 카카오의 AI 개발자로서 다양한 주제에 대해 자주 강의와 토론을 진행합니다. 특정 여행지를\n",
      "Q4: system\n",
      "\n",
      "You are a helpful AI assistant developed by Kakao.user\n",
      "\n",
      "홍정모의 취미는 무엇인가요?assistant\n",
      "\n",
      "홍정모님은 카카오의 AI 개발자로서 다양한 프로젝트와 연구에 참여하고 계십니다. 취미로는 코딩, 프\n",
      "Q5: system\n",
      "\n",
      "You are a helpful AI assistant developed by Kakao.user\n",
      "\n",
      "홍정모가 좋아하는 계절은 무엇인가요?assistant\n",
      "\n",
      "홍정모 교수님에 대한 구체적인 정보를 제공할 수는 없지만, 일반적으로 많은 사람들이 계절에 대해 가지고 있는 선호도를\n",
      "Q6: system\n",
      "\n",
      "You are a helpful AI assistant developed by Kakao.user\n",
      "\n",
      "홍정모의 특기는 무엇인가요?assistant\n",
      "\n",
      "홍정모님은 다양한 분야에서 뛰어난 능력을 보이시는 분으로, 특히 다음과 같은 특기로 잘 알려져 있습니다:\n",
      "\n",
      "1. **\n",
      "Q7: system\n",
      "\n",
      "You are a helpful AI assistant developed by Kakao.user\n",
      "\n",
      "홍정모가 자주 듣는 음악 장르는?assistant\n",
      "\n",
      "홍정모는 다양한 음악 장르를 즐기지만, 특히 다음과 같은 장르에서 자주 듣는다고 알려져 있습니다:\n",
      "\n",
      "1. **클\n",
      "Q8: system\n",
      "\n",
      "You are a helpful AI assistant developed by Kakao.user\n",
      "\n",
      "홍정모가 가장 좋아하는 색깔은?assistant\n",
      "\n",
      "홍정모 교수님에 대한 구체적인 정보를 직접적으로 제공받기 어렵지만, 일반적으로 홍정모 교수님은 다양한 분야에서\n",
      "Q9: system\n",
      "\n",
      "You are a helpful AI assistant developed by Kakao.user\n",
      "\n",
      "홍정모가 선호하는 영화 장르는?assistant\n",
      "\n",
      "홍정모 교수님은 다양한 주제와 장르에 걸쳐 폭넓은 관심을 가지고 계신 것으로 알려져 있습니다. 하지만 특정\n",
      "Q10: system\n",
      "\n",
      "You are a helpful AI assistant developed by Kakao.user\n",
      "\n",
      "홍정모가 좋아하는 운동은?assistant\n",
      "\n",
      "홍정모 선생님에 대한 구체적인 정보는 많이 알려져 있지 않지만, 일반적으로 유명한 인물들이 그렇듯이 다양한\n",
      "Q11: system\n",
      "\n",
      "You are a helpful AI assistant developed by Kakao.user\n",
      "\n",
      "홍정모는 어떤 동물을 좋아하나요?assistant\n",
      "\n",
      "홍정모는 특정한 동물에 대한 구체적인 정보를 제공한 적은 없지만, 일반적으로 과학, 수학, 철\n",
      "Q12: system\n",
      "\n",
      "You are a helpful AI assistant developed by Kakao.user\n",
      "\n",
      "홍정모가 주로 사용하는 소셜 미디어는?assistant\n",
      "\n",
      "홍정모 교수님은 주로 다음과 같은 소셜 미디어 플랫폼을 사용하십니다:\n",
      "\n",
      "1. **네이버 카페**:\n",
      "Q13: system\n",
      "\n",
      "You are a helpful AI assistant developed by Kakao.user\n",
      "\n",
      "홍정모가 좋아하는 음식은?assistant\n",
      "\n",
      "홍정모 교수님에 대한 구체적인 정보는 많이 알려져 있지 않지만, 일반적으로 유명한 교수나 학자들은 다양한 관심\n",
      "Q14: system\n",
      "\n",
      "You are a helpful AI assistant developed by Kakao.user\n",
      "\n",
      "홍정모가 가장 최근에 본 드라마는 무엇인가요?assistant\n",
      "\n",
      "제가 제공하는 정보는 2023년 9월 시점을 기준으로 합니다. 홍정모 배우가 가장 최근에 본 드라마에 대해서\n",
      "Q15: system\n",
      "\n",
      "You are a helpful AI assistant developed by Kakao.user\n",
      "\n",
      "홍정모가 싫어하는 게임은 뭔가요?assistant\n",
      "\n",
      "홍정모님에 대한 구체적인 정보는 많이 알려져 있지 않아서, 일반적으로 많은 사람들이 좋아하거나 싫어하는 특정\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "# 파인튜닝 전에 어떻게 대답하는지 확인\n",
    "\n",
    "questions = [ qna['q_ids'] for qna in qna_list]\n",
    "\n",
    "for i, q_ids in enumerate(questions):\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            torch.tensor([q_ids]),\n",
    "            max_new_tokens=32,\n",
    "            #attention_mask = (input_ids != 0).long(),\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            do_sample=False,\n",
    "            # temperature=1.2,\n",
    "            # top_k=5\n",
    "        )\n",
    "\n",
    "    output_list = output.tolist()\n",
    "\n",
    "    print(f\"Q{i}: {tokenizer.decode(output[0], skip_special_tokens=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd242c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q0: 너에 대해서 설명해봐.  A: 안녕하세요! 저는 한국에서 온 대학생이에요. 이름은 김민수이고, 20살이에요. 저는 컴퓨터 공학을 전공하고 있어요. 컴퓨터 프로그래밍과 인공지능에 관심이 많아요.  A: 반가워요! 김민수 군, 정말 멋지네요. 컴퓨터 공학을 전공하다니 대단해요. 인공지능에 대한 관심도 정말 대\n",
      "Q1: 인공지능의 장점은? 인공지능(AI)은 다양한 분야에서 혁신적인 변화를 가져오고 있습니다. 그 장점은 다음과 같습니다:\n",
      "\n",
      "1. **데이터 분석 및 예측**:\n",
      "   - 대량의 데이터를 빠르고 정확하게 분석하여 패턴을 발견하고 예측할 수 있습니다.\n",
      "   - 의료, 금융, 교통 등 다양한 분야에서 유용하게 활용됩니다.\n",
      "\n",
      "2. **자동화 및 효율성**:\n",
      "   - 반복적이고 시간\n",
      "Q2: 동아대에 대해 알려줘\n",
      "아주대와 함께 경상권을 대표하는 사립대학교 중 하나인 아시아대(아주대)는 다양한 학문 분야에서 우수한 교육을 제공하는 대학입니다. 다음은 아시아대(아주대)에 대한 주요 정보입니다:\n",
      "\n",
      "### 학교 개요\n",
      "- **학교명**: 아시아대학교(아주대)\n",
      "- **소재지**: 경상남도 창원시\n",
      "- **설립 연도**: 1997년\n",
      "\n",
      "###\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "# 질문확인\n",
    "\n",
    "questions = [\n",
    "    \"너에 대해서 설명해봐\",\n",
    "    \"인공지능의 장점은?\",\n",
    "    \"동아대에 대해 알려줘\",\n",
    "]\n",
    "\n",
    "input_ids = tokenizer(\n",
    "    questions,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")   # [\"input_ids\"].to(\"cuda\") nvidia gpu에서 사용\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model.generate(\n",
    "        input_ids[\"input_ids\"],\n",
    "        max_new_tokens=100,\n",
    "        do_sample=False,\n",
    "    )\n",
    "    \n",
    "output_list = output.tolist()\n",
    "\n",
    "for i,output in enumerate(output_list):\n",
    "    print(f\"Q{i}: {tokenizer.decode(output, skip_special_tokens=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fe18c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Tokens seen: 118\n",
      "1 Tokens seen: 236\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m loss = torch.nn.functional.cross_entropy(logits.flatten(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m), target_batch.flatten())\n\u001b[32m     19\u001b[39m epoch_loss += loss.item()\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Calculate loss gradients\u001b[39;00m\n\u001b[32m     21\u001b[39m optimizer.step() \u001b[38;5;66;03m# Update model weights using loss gradients\u001b[39;00m\n\u001b[32m     22\u001b[39m tokens_seen += input_batch.numel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gonza\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gonza\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gonza\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 파인튜닝\n",
    "tokens_seen, global_step = 0, -1\n",
    "\n",
    "losses = []\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00001, weight_decay=0.01)\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()  # 트레이닝 모드\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    for input_batch, target_batch in train_loader:\n",
    "        optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "        input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "        logits = model(input_batch).logits # 뒤에 .logits를 붙여서 tensor만 가져옴\n",
    "\n",
    "        loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward() # 손실 계산 후 역전파\n",
    "        optimizer.step() # 가중치 업데이트트\n",
    "        tokens_seen += input_batch.numel()\n",
    "        global_step += 1\n",
    "\n",
    "        print(f\"{global_step} Tokens seen: {tokens_seen}\")\n",
    "\n",
    "        # if global_step % 1000 == 0:\n",
    "        #     print(f\"Tokens seen: {tokens_seen}\")\n",
    "        # Optional evaluation step\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    losses.append(avg_loss)\n",
    "    print(f\"Epoch: {epoch}, Loss: {avg_loss}\")\n",
    "    torch.save(model.state_dict(), \"model_\" + str(epoch).zfill(3) + \".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfcbb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파인튜닝 후에 어떻게 응답하는지 확인\n",
    "\n",
    "model.load_state_dict(torch.load(\"model_009.pth\", map_location=device, weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3534c278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 그래프\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ef8bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파인튜닝 후에 어떻게 대답하는지 확인\n",
    "questions = [ qna['q_ids'] for qna in qna_list]\n",
    "\n",
    "for i, q_ids in enumerate(questions):\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            torch.tensor([q_ids]).to(\"cuda\"),\n",
    "            max_new_tokens=32,\n",
    "            #attention_mask = (input_ids != 0).long(),\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            do_sample=False,\n",
    "            # temperature=1.2,\n",
    "            # top_k=5\n",
    "        )\n",
    "\n",
    "    output_list = output.tolist()\n",
    "    print(f\"Q{i}: {tokenizer.decode(output[0], skip_special_tokens=True)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
